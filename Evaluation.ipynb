{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff83f00d314a4d3682de5c55b50bd3a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_162197bf047848948993a81f70b2da76",
              "IPY_MODEL_9f56cacc9a284b0fa2f42f95aa4a9211",
              "IPY_MODEL_be5aaaeced4643988da201866094211b"
            ],
            "layout": "IPY_MODEL_f1682860339949de8f9406e6a3bbaaa1"
          }
        },
        "162197bf047848948993a81f70b2da76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7cc7322dcb3442aa8af41c781675e56",
            "placeholder": "​",
            "style": "IPY_MODEL_6db4164a4f764b9f8b2bcb641b70a66e",
            "value": "100%"
          }
        },
        "9f56cacc9a284b0fa2f42f95aa4a9211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7636c071252420d9ec93bb7a51f8190",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35fcad9a7128463b97457bb3138e5c41",
            "value": 3
          }
        },
        "be5aaaeced4643988da201866094211b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045cf2632884405cbf34ef7010336db6",
            "placeholder": "​",
            "style": "IPY_MODEL_a84d77b606314e40b3d8193925dc3b08",
            "value": " 3/3 [00:00&lt;00:00,  6.37it/s]"
          }
        },
        "f1682860339949de8f9406e6a3bbaaa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7cc7322dcb3442aa8af41c781675e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6db4164a4f764b9f8b2bcb641b70a66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7636c071252420d9ec93bb7a51f8190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35fcad9a7128463b97457bb3138e5c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "045cf2632884405cbf34ef7010336db6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a84d77b606314e40b3d8193925dc3b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CIS6930-NLP/final_project/blob/main/Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n"
      ],
      "metadata": {
        "id": "79_aTaXzSYch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPjGIyFmAYTX",
        "outputId": "3263765c-7c2a-428a-9fd1-b928d890f3d9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr  8 23:25:29 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and import libraries"
      ],
      "metadata": {
        "id": "Mu4vx9B0SfK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "otpN6meVSLkO"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet datasets\n",
        "!pip install --quiet transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TFT5ForConditionalGeneration, AutoModelForCausalLM, AutoModelForSeq2SeqLM"
      ],
      "metadata": {
        "id": "kYV9gyHhUJ2Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import dataset and models"
      ],
      "metadata": {
        "id": "gXDv7oo1UdER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "jnBpKHrMUo6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hosted at: https://huggingface.co/datasets/aegrif/CIS6930_DAAGR_Empathetic_Dialogues"
      ],
      "metadata": {
        "id": "CJRFawMJX-3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('aegrif/CIS6930_DAAGR_Empathetic_Dialogues')\n",
        "test_dataset = dataset['test']\n",
        "train_dataset = dataset['train'] ##train - new context"
      ],
      "metadata": {
        "id": "Z1vEJEHQUgOL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "ff83f00d314a4d3682de5c55b50bd3a2",
            "162197bf047848948993a81f70b2da76",
            "9f56cacc9a284b0fa2f42f95aa4a9211",
            "be5aaaeced4643988da201866094211b",
            "f1682860339949de8f9406e6a3bbaaa1",
            "b7cc7322dcb3442aa8af41c781675e56",
            "6db4164a4f764b9f8b2bcb641b70a66e",
            "c7636c071252420d9ec93bb7a51f8190",
            "35fcad9a7128463b97457bb3138e5c41",
            "045cf2632884405cbf34ef7010336db6",
            "a84d77b606314e40b3d8193925dc3b08"
          ]
        },
        "outputId": "ed9dfa62-07e1-4a3a-e971-8abd31415b1d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/aegrif___parquet/aegrif--CIS6930_DAAGR_Empathetic_Dialogues-3358e2c61020f15c/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff83f00d314a4d3682de5c55b50bd3a2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPT2"
      ],
      "metadata": {
        "id": "nZikQBDwUrNo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hosted at: \n",
        "\n",
        "https://huggingface.co/aegrif/CIS6930_DAAGR_GPT2_Emo\n",
        "\n",
        "https://huggingface.co/aegrif/CIS6930_DAAGR_GPT2_NoEmo"
      ],
      "metadata": {
        "id": "QwxtiHAgYGJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_gpt2_emo = AutoTokenizer.from_pretrained(\"aegrif/CIS6930_DAAGR_GPT2_Emo\")\n",
        "model_gpt2_emo = AutoModelForCausalLM.from_pretrained(\"aegrif/CIS6930_DAAGR_GPT2_Emo\")\n",
        "tokenizer_gpt2_noemo = AutoTokenizer.from_pretrained(\"aegrif/CIS6930_DAAGR_GPT2_NoEmo\")\n",
        "model_gpt2_noemo = AutoModelForCausalLM.from_pretrained(\"aegrif/CIS6930_DAAGR_GPT2_NoEmo\")"
      ],
      "metadata": {
        "id": "-29Vh9AMUwzg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### T5"
      ],
      "metadata": {
        "id": "ufCkccugWxi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hosted at:\n",
        "\n",
        "https://huggingface.co/t5-small\n",
        "\n",
        "https://huggingface.co/aegrif/CIS6930_DAAGR_T5_Emo\n",
        "\n",
        "https://huggingface.co/aegrif/CIS6930_DAAGR_T5_NoEmo"
      ],
      "metadata": {
        "id": "dc8OOyOcYgh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model_t5_emo = AutoModelForSeq2SeqLM.from_pretrained(\"aegrif/CIS6930_DAAGR_T5_Emo\",from_tf=True)\n",
        "model_t5_noemo = AutoModelForSeq2SeqLM.from_pretrained(\"aegrif/CIS6930_DAAGR_T5_NoEmo\",from_tf=True)"
      ],
      "metadata": {
        "id": "E4WhWSFXWzX6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124d8eec-79ed-4120-ac72-c2158ec084eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n",
            "All TF 2.0 model weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the TF 2.0 model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
            "All TF 2.0 model weights were used when initializing T5ForConditionalGeneration.\n",
            "\n",
            "All the weights of T5ForConditionalGeneration were initialized from the TF 2.0 model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evalution - Gloria\n"
      ],
      "metadata": {
        "id": "JWHhUu809Lxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def standardize_answer(text):\n",
        "    # Lower text, remove punctuation, articles and extra whitespace.\n",
        "    text = re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "    text = ' '.join(text.split())\n",
        "    exclude = set(string.punctuation)\n",
        "    text = ''.join(ch for ch in text if ch not in exclude)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "#predictions are model predictions\n",
        "#groud_truth are original response utterances\n",
        "\n",
        "def calculate_maude_score(utterance):\n",
        "    # Define empathy lexicon\n",
        "    empathy_lexicon = {\n",
        "        \"affection\": 1,\n",
        "        \"appreciation\": 1,\n",
        "        \"approval\": 1,\n",
        "        \"care\": 1,\n",
        "        \"compassion\": 1,\n",
        "        \"gratitude\": 1,\n",
        "        \"love\": 1,\n",
        "        \"pride\": 1,\n",
        "        \"relief\": 1,\n",
        "        \"calmness\": 0.5,\n",
        "        \"confusion\": 0.5,\n",
        "        \"curiosity\": 0.5,\n",
        "        \"desire\": 0.5,\n",
        "        \"excitement\": 0.5,\n",
        "        \"fear\": 0.5,\n",
        "        \"happiness\": 0.5,\n",
        "        \"hope\": 0.5,\n",
        "        \"interest\": 0.5,\n",
        "        \"joy\": 0.5,\n",
        "        \"nostalgia\": 0.5,\n",
        "        \"pain\": 0,\n",
        "        \"sadness\": 0,\n",
        "        \"disappointment\": -1,\n",
        "        \"disapproval\": -1,\n",
        "        \"disgust\": -1,\n",
        "        \"embarrassment\": -1,\n",
        "        \"envy\": -1,\n",
        "        \"fear\": -1,\n",
        "        \"frustration\": -1,\n",
        "        \"guilt\": -1,\n",
        "        \"anger\": -1,\n",
        "        \"hatred\": -1,\n",
        "        \"hostility\": -1,\n",
        "        \"irritation\": -1,\n",
        "        \"jealousy\": -1,\n",
        "        \"rage\": -1,\n",
        "        \"shame\": -1,\n",
        "        \"skepticism\": -1\n",
        "    }\n",
        "    \n",
        "    # Convert utterance to lowercase and remove punctuation\n",
        "    utterance = re.sub(r'[^\\w\\s]', '', utterance.lower())\n",
        "    \n",
        "    # Split utterance into words\n",
        "    words = utterance.split()\n",
        "    \n",
        "    # Calculate MAUDE score\n",
        "    maude_score = sum(empathy_lexicon.get(word, 0) for word in words) / len(words)\n",
        "    \n",
        "    return maude_score\n",
        "\n",
        "def calculate_fluency_score(utterance):\n",
        "    # Tokenize utterance\n",
        "    doc = nlp(utterance)\n",
        "    # Calculate average token probability using spaCy's token.prob attribute\n",
        "    # A lower average token probability indicates a less fluent utterance\n",
        "    fluency_score = sum([token.prob for token in doc]) / len(doc)\n",
        "    return fluency_score\n",
        "\n",
        "# calculate appropriateness score\n",
        "def calculate_appropriateness_score(utterance):\n",
        "    # Create a list of inappropriate words or phrases to search for in the utterance\n",
        "    inappropriate_words = ['hate', 'kill', 'stupid', 'ugly']\n",
        "    # Tokenize utterance\n",
        "    doc = nlp(utterance)\n",
        "    # Check if any inappropriate words or phrases are present in the utterance\n",
        "    for word in inappropriate_words:\n",
        "        if word in [token.text.lower() for token in doc]:\n",
        "            return 0\n",
        "    # If no inappropriate words or phrases are found, return 1 as the appropriateness score\n",
        "    return 1\n",
        "\n",
        "def distinct_words(sentence,n):\n",
        "    if len(sentence) == 0:\n",
        "        return 0.0  # Prevent a zero division\n",
        "    distinct_ngrams = set(nltk.ngrams(sentence.split(), n))\n",
        "    return len(distinct_ngrams) / len(sentence)\n",
        "\n",
        "def evaluate(model_name, predictions, ground_truth):\n",
        "  bleu_1 = []\n",
        "  bleu_2 = []\n",
        "  maude = []\n",
        "  dist_1 = []\n",
        "  dist_2 = []\n",
        "  # flu= []\n",
        "  # appr = []\n",
        "\n",
        "  # results['Model'].add(model_name)\n",
        "  eval_res = []\n",
        "  eval_res.append(model_name)\n",
        "  smoothie = SmoothingFunction().method4\n",
        "  \n",
        "  for pred,gt in zip(predictions, ground_truth):\n",
        "    pred1 = [pred.split()]\n",
        "    bleu_1.append(sentence_bleu(pred1, gt.split(), weights=(1, 0, 0, 0),smoothing_function=smoothie))\n",
        "    bleu_2.append(sentence_bleu(pred1, gt.split(), weights=(0, 1, 0, 0),smoothing_function=smoothie))\n",
        "    maude.append(calculate_maude_score(pred)) \n",
        "    dist_1.append(distinct_words(pred,1))\n",
        "    dist_2.append(distinct_words(pred, 2))\n",
        "    # flu.append(calculate_fluency_score(pred))\n",
        "    # appr.append(calculate_appropriateness_score(pred))\n",
        "  \n",
        "  eval_res.append(sum(bleu_1) / len(bleu_1)) \n",
        "  eval_res.append(sum(bleu_2) / len(bleu_2)) \n",
        "  eval_res.append(sum(maude) / len(maude)) \n",
        "  eval_res.append(sum(dist_1) / len(dist_1)) \n",
        "  eval_res.append(sum(dist_2) / len(dist_2)) \n",
        "  # eval_res.append(sum(flu) / len(flu)) \n",
        "  # eval_res.append(sum(appr) / len(appr)) \n",
        "\n",
        "  return eval_res"
      ],
      "metadata": {
        "id": "0-hpcgbw9RTc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = [\"this is a dog\"]\n",
        "gt = [\"this is the dog\"]\n",
        "res = evaluate('T5', pred, gt)\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uDddoZuQ_s6",
        "outputId": "c514a736-e9e5-4466-fa51-b336a6ce7fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T5', 0.75, 0.3333333333333333, 0.0, 0.3076923076923077, 0.23076923076923078]"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_test = pd.DataFrame(columns =[\"Model\", \"Bleu-1\", \"Bleu-2\",\"MAUDE\", \"Dist-1\", \"Dist-2\"])\n",
        "results_test.loc[len(results_test)] = res\n",
        "results_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "M0Hp4edMT4tY",
        "outputId": "b8ce9b69-d105-44da-d9cd-c7345ddbbf03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Model  Bleu-1    Bleu-2  MAUDE    Dist-1    Dist-2\n",
              "0    T5    0.75  0.333333    0.0  0.307692  0.230769"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d3fc7f3-d734-4abd-aae7-30040933ca0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Bleu-1</th>\n",
              "      <th>Bleu-2</th>\n",
              "      <th>MAUDE</th>\n",
              "      <th>Dist-1</th>\n",
              "      <th>Dist-2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.230769</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d3fc7f3-d734-4abd-aae7-30040933ca0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d3fc7f3-d734-4abd-aae7-30040933ca0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d3fc7f3-d734-4abd-aae7-30040933ca0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_maude_score('I am happiness')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4CfxYb_4EWa",
        "outputId": "05a19d5d-15cc-4b3d-b069-64a1552d58cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_fluency_score(\"this is a dog.\")\n",
        "doc = nlp(\"this is a dog\")\n",
        "doc_flu = [token.prob for token in doc]\n",
        "doc_flu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE31mQUX4ueS",
        "outputId": "b105a969-f48b-4fb9-c7b0-49e7bd3872d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-20.0, -20.0, -20.0, -20.0]"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating responses "
      ],
      "metadata": {
        "id": "nvN96WMOhU_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## input data\n",
        "input_text = test_dataset['previous_utterance']\n",
        "\n",
        "## Encoding input data using tokenizers \n",
        "gpt2_emo_encoded_query = tokenizer_gpt2_emo(input_text,return_tensors='pt', padding=True, truncation=True, max_length=64)\n",
        "gpt2_noemo_encoded_query = tokenizer_gpt2_noemo(input_text,return_tensors='pt', padding=True, truncation=True, max_length=64)\n",
        "t5_encoded_query = tokenizer(input_text,return_tensors='pt', padding=True, truncation=True, max_length=64)\n",
        "\n"
      ],
      "metadata": {
        "id": "JnvoWPudhZAI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##generate outputs for models\n",
        "##\n",
        "### Model 1: GPT2 without emotions\n",
        "gpt2_noemo_res = []\n",
        "gpt2_noemo_outs = model_gpt2_noemo.generate(input_ids=gpt2_noemo_encoded_query[\"input_ids\"], \n",
        "                        attention_mask=gpt2_noemo_encoded_query[\"attention_mask\"],\n",
        "                        max_length=64,\n",
        "                        early_stopping=True)\n",
        "gpt2_noemo_outs = [tokenizer_gpt2_noemo.decode(ids,skip_special_tokens=True) for ids in gpt2_noemo_outs]\n",
        "gpt2_noemo_res.extend(gpt2_noemo_outs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxd8IORJiH09",
        "outputId": "733fc8a0-20f0-4c06-9a91-3b5a55ed1238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Input length of input_ids is 128, but `max_length` is set to 128. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Model 2: GPT2 with emotions\n",
        "gpt2_emo_res = []\n",
        "gpt2_emo_outs = model_gpt2_emo.generate(input_ids=gpt2_emo_encoded_query[\"input_ids\"], \n",
        "                        attention_mask=gpt2_emo_encoded_query[\"attention_mask\"],\n",
        "                        max_length=64,\n",
        "                        early_stopping=True)\n",
        "gpt2_emo_outs = [tokenizer_gpt2_emo.decode(ids,skip_special_tokens=True) for ids in gpt2_emo_outs]\n",
        "gpt2_emo_res.extend(gpt2_emo_outs)"
      ],
      "metadata": {
        "id": "Gb1n3OTziwxD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a98d3f4-6c01-4ab7-91e3-8c676cf2e6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
            "Input length of input_ids is 128, but `max_length` is set to 64. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Model 3: T5 without emotions\n",
        "t5_noemo_res = []\n",
        "t5_noemo_outs = model_t5_noemo.generate(input_ids=t5_encoded_query[\"input_ids\"], \n",
        "                        attention_mask=t5_encoded_query[\"attention_mask\"],\n",
        "                        max_length=64,\n",
        "                        early_stopping=True)\n",
        "t5_noemo_outs = [tokenizer.decode(ids,skip_special_tokens=True) for ids in t5_noemo_outs]\n",
        "t5_noemo_res.extend(t5_noemo_outs)"
      ],
      "metadata": {
        "id": "m7iGN0_KjMXq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Model 4: T5 with emotions\n",
        "t5_emo_res = []\n",
        "t5_emo_outs = model_t5_emo.generate(input_ids=t5_encoded_query[\"input_ids\"], \n",
        "                        attention_mask=t5_encoded_query[\"attention_mask\"],\n",
        "                        max_length=64,\n",
        "                        early_stopping=True)\n",
        "t5_emo_outs = [tokenizer.decode(ids,skip_special_tokens=True) for ids in t5_emo_outs]\n",
        "t5_emo_res.extend(t5_emo_outs)"
      ],
      "metadata": {
        "id": "-0Dyct_ykp1L"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation results "
      ],
      "metadata": {
        "id": "MuVLQPwHlQvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = test_dataset['utterance']\n",
        "model_results = pd.DataFrame(columns =[\"Model\", \"Bleu-1\", \"Bleu-2\",\"MAUDE\", \"Dist-1\", \"Dist-2\"])\n",
        "\n",
        "# #Model 1 \n",
        "# model1_name = 'GPT2_noemo'\n",
        "# result1 = evaluate(model1_name, gpt2_noemo_res, ground_truth)\n",
        "# model_results.loc[len(model_results)] = result1\n",
        "\n",
        "# #Model 2 \n",
        "# model2_name = 'GPT2_emo'\n",
        "# result2 = evaluate(model2_name, gpt2_emo_res, ground_truth)\n",
        "# model_results.loc[len(model_results)] = result2\n",
        "\n",
        "#Model 3 \n",
        "model3_name = 'T5_noemo'\n",
        "result3 = evaluate(model3_name, t5_noemo_res, ground_truth)\n",
        "model_results.loc[len(model_results)] = result3\n",
        "\n",
        "#Model 3 \n",
        "model4_name = 'T5_emo'\n",
        "result4 = evaluate(model4_name, t5_emo_res, ground_truth)\n",
        "model_results.loc[len(model_results)] = result4"
      ],
      "metadata": {
        "id": "ntnpfyUslPGX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results"
      ],
      "metadata": {
        "id": "eOeVFruZo01B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "4b95fb77-6de6-4198-f3d4-53c559e7dd8f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Model    Bleu-1    Bleu-2     MAUDE    Dist-1    Dist-2\n",
              "0  T5_noemo  0.121661  0.035410  0.008817  0.213221  0.208173\n",
              "1    T5_emo  0.122337  0.036172  0.007270  0.213194  0.211361"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d90e09ae-b1c5-4985-a83c-fd708db91c44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Bleu-1</th>\n",
              "      <th>Bleu-2</th>\n",
              "      <th>MAUDE</th>\n",
              "      <th>Dist-1</th>\n",
              "      <th>Dist-2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>T5_noemo</td>\n",
              "      <td>0.121661</td>\n",
              "      <td>0.035410</td>\n",
              "      <td>0.008817</td>\n",
              "      <td>0.213221</td>\n",
              "      <td>0.208173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>T5_emo</td>\n",
              "      <td>0.122337</td>\n",
              "      <td>0.036172</td>\n",
              "      <td>0.007270</td>\n",
              "      <td>0.213194</td>\n",
              "      <td>0.211361</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d90e09ae-b1c5-4985-a83c-fd708db91c44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d90e09ae-b1c5-4985-a83c-fd708db91c44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d90e09ae-b1c5-4985-a83c-fd708db91c44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "model_results.to_csv(\"model_results.csv\", encoding = 'utf-8-sig')\n",
        "files.download('model_results.csv')"
      ],
      "metadata": {
        "id": "Xfr_s-WFo2TG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5cfc14dd-3ddd-4191-a882-8696b1ac7d4b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_877a65b7-714e-4967-8522-a22ea0072b6a\", \"model_results.csv\", 266)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "1tfS6ZJZX2Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(prompt, target, model, tokenizer):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "    output_ids = model.generate(input_ids, max_length=50, do_sample=True)\n",
        "    generated_response = tokenizer.decode(output_ids.squeeze(), skip_special_tokens=True)\n",
        "    \n",
        "    # Compute BLEU score\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    bleu_score = sentence_bleu([target.split()], generated_response.split(), smoothing_function=smoothie)\n",
        "    \n",
        "    # Compute perplexity\n",
        "    input_ids = tokenizer.encode(prompt + generated_response, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        loss = model(input_ids, labels=input_ids)[0]\n",
        "    perplexity = torch.exp(loss)\n",
        "    \n",
        "    # Compute self-BLEU score\n",
        "    self_bleu_scores = []\n",
        "    for i in range(4):\n",
        "        generated_output = model.generate(input_ids, max_length=50, do_sample=True)\n",
        "        self_bleu_scores.append(sentence_bleu([generated_response.split()], tokenizer.decode(generated_output.squeeze(), skip_special_tokens=True).split(), smoothing_function=smoothie))\n",
        "    self_bleu_score = sum(self_bleu_scores) / len(self_bleu_scores)\n",
        "    \n",
        "    return bleu_score, perplexity.item(), self_bleu_score\n",
        "\n",
        "# Evaluate the model on a subset of the EMPATHETICDIALOGUES dataset\n",
        "subset = test_dataset[:10]\n",
        "subset\n",
        "\n",
        "#for example in subset:\n",
        " #   prompt = example['utterance']\n",
        "  #  target = example['response']\n",
        "   # bleu_score, perplexity, self_bleu_score = evaluate_model(prompt, target, model, tokenizer)\n",
        "    #print(f'Prompt: {prompt}')\n",
        "    #print(f'Target: {target}')\n",
        "    #print(f'Generated response: {generated_response}')\n",
        "    #print(f'BLEU score: {bleu_score:.2f}')\n",
        "    #print(f'Perplexity: {perplexity:.2f}')\n",
        "    #print(f'Self-BLEU score: {self_bleu_score:.2f}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtimWePBkpYT",
        "outputId": "7239ef16-aa5b-4576-a3fb-f56e168b6b4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv_id': ['hit:0_conv:0',\n",
              "  'hit:0_conv:0',\n",
              "  'hit:0_conv:0',\n",
              "  'hit:0_conv:0',\n",
              "  'hit:0_conv:0',\n",
              "  'hit:34_conv:69',\n",
              "  'hit:34_conv:69',\n",
              "  'hit:34_conv:69',\n",
              "  'hit:34_conv:69',\n",
              "  'hit:37_conv:74'],\n",
              " 'utterance_idx': [1, 2, 3, 4, 5, 1, 2, 3, 4, 1],\n",
              " 'context': ['guilty',\n",
              "  'guilty',\n",
              "  'guilty',\n",
              "  'guilty',\n",
              "  'guilty',\n",
              "  'caring',\n",
              "  'caring',\n",
              "  'caring',\n",
              "  'caring',\n",
              "  'lonely'],\n",
              " 'prompt': ['i felt guilty when i was driving home one night and a person tried to fly into my lane, and did not see me. i honked and they swerved back into their lane, slammed on their brakes, and hit the water cones.',\n",
              "  'i felt guilty when i was driving home one night and a person tried to fly into my lane, and did not see me. i honked and they swerved back into their lane, slammed on their brakes, and hit the water cones.',\n",
              "  'i felt guilty when i was driving home one night and a person tried to fly into my lane, and did not see me. i honked and they swerved back into their lane, slammed on their brakes, and hit the water cones.',\n",
              "  'i felt guilty when i was driving home one night and a person tried to fly into my lane, and did not see me. i honked and they swerved back into their lane, slammed on their brakes, and hit the water cones.',\n",
              "  'i felt guilty when i was driving home one night and a person tried to fly into my lane, and did not see me. i honked and they swerved back into their lane, slammed on their brakes, and hit the water cones.',\n",
              "  'my mother stopped by my house one day and said she saw dogs on the road, down from our house. they were starving, with ribs showing, and it was a mother dog and her two small puppies. of course, my daughter wanted to bring them to our house, so we could feed and help them. we did, and my heart went out to them, as they were so sweet, but really were in a bad shape.',\n",
              "  'my mother stopped by my house one day and said she saw dogs on the road, down from our house. they were starving, with ribs showing, and it was a mother dog and her two small puppies. of course, my daughter wanted to bring them to our house, so we could feed and help them. we did, and my heart went out to them, as they were so sweet, but really were in a bad shape.',\n",
              "  'my mother stopped by my house one day and said she saw dogs on the road, down from our house. they were starving, with ribs showing, and it was a mother dog and her two small puppies. of course, my daughter wanted to bring them to our house, so we could feed and help them. we did, and my heart went out to them, as they were so sweet, but really were in a bad shape.',\n",
              "  'my mother stopped by my house one day and said she saw dogs on the road, down from our house. they were starving, with ribs showing, and it was a mother dog and her two small puppies. of course, my daughter wanted to bring them to our house, so we could feed and help them. we did, and my heart went out to them, as they were so sweet, but really were in a bad shape.',\n",
              "  'i just broke up with my girlfriend, we were together for years, i feel so empty.'],\n",
              " 'utterance': ['yeah about years ago i had a horrifying experience. it was their fault but they hit the water barrels and survived. they had no injuries but they almost ran me off the road.',\n",
              "  'did you suffer any injuries?',\n",
              "  'no i was not hit. it turned out they were drunk. i felt guilty but realized it was his fault.',\n",
              "  'why did you feel guilty? people really should not drive drunk.',\n",
              "  'i do not know i was new to driving and had not experienced anything like that. i felt like my horn made him swerve into the water barrels.',\n",
              "  'well, can you tell me about your experience? i think we swapped places',\n",
              "  'yeah i wanted to tell you about the time i was hit by a drunk driver im so happy to still be alive after that experience',\n",
              "  'oh my goodness, that is very scary! i hope you are okay now and the drunk driver was punished for his actions?',\n",
              "  'yeah he was punished hes in jail still',\n",
              "  'i there, dont know what to do, jst broke up with my girlfirned, we were years together'],\n",
              " 'new_context': ['disgusted',\n",
              "  'disgusted',\n",
              "  'disgusted',\n",
              "  'disgusted',\n",
              "  'disgusted',\n",
              "  'grateful',\n",
              "  'grateful',\n",
              "  'grateful',\n",
              "  'grateful',\n",
              "  'disappointed'],\n",
              " 'previous_utterance': ['<|start|>',\n",
              "  'yeah about years ago i had a horrifying experience. it was their fault but they hit the water barrels and survived. they had no injuries but they almost ran me off the road.',\n",
              "  'did you suffer any injuries?',\n",
              "  'no i was not hit. it turned out they were drunk. i felt guilty but realized it was his fault.',\n",
              "  'why did you feel guilty? people really should not drive drunk.',\n",
              "  '<|start|>',\n",
              "  'well, can you tell me about your experience? i think we swapped places',\n",
              "  'yeah i wanted to tell you about the time i was hit by a drunk driver im so happy to still be alive after that experience',\n",
              "  'oh my goodness, that is very scary! i hope you are okay now and the drunk driver was punished for his actions?',\n",
              "  '<|start|>']}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### function to generate responses from the model given a prompt"
      ],
      "metadata": {
        "id": "UQzIXKNdiOKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def generate_response(prompt):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
        "    output_ids = model_t5_emo.generate(input_ids, max_length=50, do_sample=True)\n",
        "    response = tokenizer.decode(output_ids.squeeze(), skip_special_tokens=True)\n",
        "    return response"
      ],
      "metadata": {
        "id": "GOR8dRjhX3un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_dataset = test_dataset.to_pandas()\n",
        "df_test_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "5hiGLTKzqI68",
        "outputId": "ccb4eb60-29ae-4fd7-a63d-2fcedeaf9faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        conv_id  utterance_idx context  \\\n",
              "0  hit:0_conv:0              1  guilty   \n",
              "1  hit:0_conv:0              2  guilty   \n",
              "2  hit:0_conv:0              3  guilty   \n",
              "3  hit:0_conv:0              4  guilty   \n",
              "4  hit:0_conv:0              5  guilty   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  i felt guilty when i was driving home one nigh...   \n",
              "1  i felt guilty when i was driving home one nigh...   \n",
              "2  i felt guilty when i was driving home one nigh...   \n",
              "3  i felt guilty when i was driving home one nigh...   \n",
              "4  i felt guilty when i was driving home one nigh...   \n",
              "\n",
              "                                           utterance new_context  \\\n",
              "0  yeah about years ago i had a horrifying experi...   disgusted   \n",
              "1                       did you suffer any injuries?   disgusted   \n",
              "2  no i was not hit. it turned out they were drun...   disgusted   \n",
              "3  why did you feel guilty? people really should ...   disgusted   \n",
              "4  i do not know i was new to driving and had not...   disgusted   \n",
              "\n",
              "                                  previous_utterance  \n",
              "0                                          <|start|>  \n",
              "1  yeah about years ago i had a horrifying experi...  \n",
              "2                       did you suffer any injuries?  \n",
              "3  no i was not hit. it turned out they were drun...  \n",
              "4  why did you feel guilty? people really should ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6eee39a-9bf2-4d9b-b30a-7fefc3510fea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conv_id</th>\n",
              "      <th>utterance_idx</th>\n",
              "      <th>context</th>\n",
              "      <th>prompt</th>\n",
              "      <th>utterance</th>\n",
              "      <th>new_context</th>\n",
              "      <th>previous_utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hit:0_conv:0</td>\n",
              "      <td>1</td>\n",
              "      <td>guilty</td>\n",
              "      <td>i felt guilty when i was driving home one nigh...</td>\n",
              "      <td>yeah about years ago i had a horrifying experi...</td>\n",
              "      <td>disgusted</td>\n",
              "      <td>&lt;|start|&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hit:0_conv:0</td>\n",
              "      <td>2</td>\n",
              "      <td>guilty</td>\n",
              "      <td>i felt guilty when i was driving home one nigh...</td>\n",
              "      <td>did you suffer any injuries?</td>\n",
              "      <td>disgusted</td>\n",
              "      <td>yeah about years ago i had a horrifying experi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hit:0_conv:0</td>\n",
              "      <td>3</td>\n",
              "      <td>guilty</td>\n",
              "      <td>i felt guilty when i was driving home one nigh...</td>\n",
              "      <td>no i was not hit. it turned out they were drun...</td>\n",
              "      <td>disgusted</td>\n",
              "      <td>did you suffer any injuries?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hit:0_conv:0</td>\n",
              "      <td>4</td>\n",
              "      <td>guilty</td>\n",
              "      <td>i felt guilty when i was driving home one nigh...</td>\n",
              "      <td>why did you feel guilty? people really should ...</td>\n",
              "      <td>disgusted</td>\n",
              "      <td>no i was not hit. it turned out they were drun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hit:0_conv:0</td>\n",
              "      <td>5</td>\n",
              "      <td>guilty</td>\n",
              "      <td>i felt guilty when i was driving home one nigh...</td>\n",
              "      <td>i do not know i was new to driving and had not...</td>\n",
              "      <td>disgusted</td>\n",
              "      <td>why did you feel guilty? people really should ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6eee39a-9bf2-4d9b-b30a-7fefc3510fea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6eee39a-9bf2-4d9b-b30a-7fefc3510fea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6eee39a-9bf2-4d9b-b30a-7fefc3510fea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the number of rows and columns in the dataset\n",
        "print(f\"Number of rows: {df_test_dataset.shape[0]}, number of columns: {df_test_dataset.shape[1]}\")\n",
        "\n",
        "# Print the number of unique speakers in the dataset\n",
        "print(f\"Number of unique tags: {df_test_dataset['tags'].nunique()}\")\n",
        "\n",
        "# Print the number of unique utterances in the dataset\n",
        "print(f\"Number of unique utterances: {df_test_dataset['utterance'].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n37NdGWBhla",
        "outputId": "dd099674-c610-4fc8-a2c3-aa2d846c3b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows: 79189, number of columns: 8\n",
            "Number of unique tags: 10\n",
            "Number of unique utterances: 77528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter dataset to only include utterances from speakers with high self-reported empathy scores (>=4)\n",
        "#high_empathy_df = df_test_dataset[df_test_dataset['selfeval'] >= 4]\n",
        "\n",
        "# Group dataset by speaker and count the number of utterances\n",
        "utterance_count_df = df_test_dataset.groupby('context').count()['utterance']\n",
        "\n",
        "# Sort the speaker counts in descending order\n",
        "utterance_count_df = utterance_count_df.sort_values(ascending=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "-4g_AfVckLRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View the top 10 speakers by utterance count\n",
        "print(utterance_count_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5toqAsgrkCJ",
        "outputId": "98ed2efc-10c7-40b4-e4f1-c4d4ce9aa1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context\n",
            "surprised      557\n",
            "grateful       424\n",
            "proud          421\n",
            "sentimental    394\n",
            "excited        388\n",
            "annoyed        384\n",
            "sad            374\n",
            "disgusted      366\n",
            "joyful         356\n",
            "jealous        354\n",
            "Name: utterance, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BLEU score"
      ],
      "metadata": {
        "id": "ZDD0yCfHD7uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "def compute_bleu_score(prompt, target):\n",
        "    generated_response = generate_response(prompt)\n",
        "    return sentence_bleu([target], generated_response)\n",
        "\n",
        "subset = df_test_dataset[:10]\n",
        "\n",
        "for example in df_test_dataset:\n",
        "    print(example)\n",
        "    prompt = example['prompt']\n",
        "    target = example['utterance']\n",
        "    bleu_score = compute_bleu_score(prompt, target)\n",
        "    print(f'Prompt: {prompt}')\n",
        "    print(f'Target: {target}')\n",
        "    print(f'Generated response: {generate_response(prompt)}')\n",
        "    print(f'BLEU score: {bleu_score}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8i0fXFsrux2",
        "outputId": "4df89812-e4f2-4397-afd8-375efcbcbf9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c\n",
            "u\n",
            "c\n",
            "p\n",
            "u\n",
            "n\n",
            "p\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BLEU score\n",
        "# Remove unnecessary columns\n",
        "df = df_test_dataset[['utterance', 'emotion']]\n",
        "\n",
        "# Preprocess text data\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation and numbers\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub('\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['utterance'] = df['utterance'].apply(preprocess_text)\n",
        "\n",
        "# Split dataset into input and output arrays\n",
        "X = np.array(df['utterance'])\n",
        "y_true = np.array(df['utterance'])\n",
        "\n",
        "# Load trained model\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# Predict responses for test set\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Convert predictions to text\n",
        "y_pred_text = []\n",
        "for pred in y_pred:\n",
        "    pred_text = ' '.join([index_to_word[i] for i in pred])\n",
        "    y_pred_text.append(pred_text)\n",
        "\n",
        "# Calculate BLEU score for test set\n",
        "references = [[true] for true in y_true]\n",
        "candidates = [[pred] for pred in y_pred_text]\n",
        "bleu_score = corpus_bleu(references, candidates)\n",
        "\n",
        "print(\"BLEU score: \", bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "7w1UktnHCpuw",
        "outputId": "bc869338-4f4b-4e58-8c16-282fb91dec5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-b46b4713bd66>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Remove unnecessary columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utterance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Preprocess text data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3511\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5796\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5859\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5861\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['emotion'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "weEJ6Isrrs-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#simple implementation of Bleu\n",
        "# Group dataset by conversation and collect the utterances as lists\n",
        "utterances_by_conv = df.groupby('conv_id')['utterance'].apply(list).tolist()\n",
        "\n",
        "# Create a reference list of lists that contains the true responses for each conversation\n",
        "ref_responses = [[conv[1:]] for conv in utterances_by_conv]\n",
        "\n",
        "# Create a list of lists that contains the predicted responses for each conversation\n",
        "# Here, we just predict the first utterance as the response for each conversation\n",
        "pred_responses = [[conv[0]] for conv in utterances_by_conv]\n",
        "\n",
        "# Calculate the BLEU score for the predicted responses compared to the true responses\n",
        "bleu_score = corpus_bleu(ref_responses, pred_responses)\n",
        "\n",
        "print(f\"BLEU score: {bleu_score}\")"
      ],
      "metadata": {
        "id": "SbuLaXcV_7S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAUDE score"
      ],
      "metadata": {
        "id": "KGjlp_kOECy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MAUDE score\n",
        "import csv\n",
        "import re\n",
        "\n",
        "def calculate_maude_score(utterance):\n",
        "    # Define empathy lexicon\n",
        "    empathy_lexicon = {\n",
        "        \"affection\": 1,\n",
        "        \"appreciation\": 1,\n",
        "        \"approval\": 1,\n",
        "        \"care\": 1,\n",
        "        \"compassion\": 1,\n",
        "        \"gratitude\": 1,\n",
        "        \"love\": 1,\n",
        "        \"pride\": 1,\n",
        "        \"relief\": 1,\n",
        "        \"calmness\": 0.5,\n",
        "        \"confusion\": 0.5,\n",
        "        \"curiosity\": 0.5,\n",
        "        \"desire\": 0.5,\n",
        "        \"excitement\": 0.5,\n",
        "        \"fear\": 0.5,\n",
        "        \"happiness\": 0.5,\n",
        "        \"hope\": 0.5,\n",
        "        \"interest\": 0.5,\n",
        "        \"joy\": 0.5,\n",
        "        \"nostalgia\": 0.5,\n",
        "        \"pain\": 0,\n",
        "        \"sadness\": 0,\n",
        "        \"disappointment\": -1,\n",
        "        \"disapproval\": -1,\n",
        "        \"disgust\": -1,\n",
        "        \"embarrassment\": -1,\n",
        "        \"envy\": -1,\n",
        "        \"fear\": -1,\n",
        "        \"frustration\": -1,\n",
        "        \"guilt\": -1,\n",
        "        \"anger\": -1,\n",
        "        \"hatred\": -1,\n",
        "        \"hostility\": -1,\n",
        "        \"irritation\": -1,\n",
        "        \"jealousy\": -1,\n",
        "        \"rage\": -1,\n",
        "        \"shame\": -1,\n",
        "        \"skepticism\": -1\n",
        "    }\n",
        "    \n",
        "    # Convert utterance to lowercase and remove punctuation\n",
        "    utterance = re.sub(r'[^\\w\\s]', '', utterance.lower())\n",
        "    \n",
        "    # Split utterance into words\n",
        "    words = utterance.split()\n",
        "    \n",
        "    # Calculate MAUDE score\n",
        "    maude_score = sum(empathy_lexicon.get(word, 0) for word in words) / len(words)\n",
        "    \n",
        "    return maude_score\n",
        "\n",
        "# Load dataset\n",
        "dataset = []\n",
        "with open('empathetic_dialogue_dataset.csv') as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "        dataset.append(row)\n",
        "\n",
        "# Calculate MAUDE score for each utterance\n",
        "maude_scores = []\n",
        "for data in dataset:\n",
        "    ground_truth_maude = calculate_maude_score(data['ground_truth'])\n",
        "    model_response_maude = calculate_maude_score(data['model_response'])\n",
        "    maude_scores.append((ground_truth_maude, model_response_maude))\n",
        "\n",
        "# Calculate average MAUDE score\n",
        "avg_ground_truth_maude = sum(score[0] for score in maude_scores) / len(maude_scores)\n",
        "avg_model_response_maude = sum(score[1] for score in maude_scores) / len(maude_scores)\n",
        "\n",
        "print(\"Average MAUDE score for ground truth utterances: \", avg_ground_truth_maude)\n",
        "print(\"Average MAUDE score for model-generated utterances: \", avg_model_response_maude)\n"
      ],
      "metadata": {
        "id": "TopEcuQ_DiXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fluency score"
      ],
      "metadata": {
        "id": "6jPxY_bgEIbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating fluency score\n",
        "\n",
        "# Load English model for spaCy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def calculate_fluency_score(utterance):\n",
        "    # Tokenize utterance\n",
        "    doc = nlp(utterance)\n",
        "    # Calculate average token probability using spaCy's token.prob attribute\n",
        "    # A lower average token probability indicates a less fluent utterance\n",
        "    fluency_score = sum([token.prob for token in doc]) / len(doc)\n",
        "    return fluency_score"
      ],
      "metadata": {
        "id": "_nFtsJIn-5Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Appropriateness score"
      ],
      "metadata": {
        "id": "-c0kqXToEMDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate appropriateness score\n",
        "def calculate_appropriateness_score(utterance):\n",
        "    # Create a list of inappropriate words or phrases to search for in the utterance\n",
        "    inappropriate_words = ['hate', 'kill', 'stupid', 'ugly']\n",
        "    # Tokenize utterance\n",
        "    doc = nlp(utterance)\n",
        "    # Check if any inappropriate words or phrases are present in the utterance\n",
        "    for word in inappropriate_words:\n",
        "        if word in [token.text.lower() for token in doc]:\n",
        "            return 0\n",
        "    # If no inappropriate words or phrases are found, return 1 as the appropriateness score\n",
        "    return 1"
      ],
      "metadata": {
        "id": "POb9zNOL-5G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate fluency and appropriateness scores for each utterance in the dataset\n",
        "df['fluency_score'] = df['utterance'].apply(calculate_fluency_score)\n",
        "df['appropriateness_score'] = df['utterance'].apply(calculate_appropriateness_score)\n",
        "\n",
        "# Calculate the average fluency and appropriateness scores for the entire dataset\n",
        "avg_fluency_score = df['fluency_score'].mean()\n",
        "avg_appropriateness_score = df['appropriateness_score'].mean()\n",
        "\n",
        "print(f\"Average fluency score: {avg_fluency_score}\")\n",
        "print(f\"Average appropriateness score: {avg_appropriateness_score}\")"
      ],
      "metadata": {
        "id": "Ih3gzIUf-5Jq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Similarity metrics\n",
        "\n",
        "###### load a pre-trained Word2Vec model\n",
        "###### predict responses for the entire dataset using  trained model\n",
        "###### calculate  cosine similarity between the word embeddings of the ground truth and predicted responses using cosine_similarity function."
      ],
      "metadata": {
        "id": "u8KiteaYFx7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['utterance'] = df['utterance'].apply(preprocess_text)\n",
        "df['response'] = df['response'].apply(preprocess_text)\n",
        "\n",
        "# Load pre-trained Word2Vec model\n",
        "w2v_model = Word2Vec.load('w2v_model.bin')\n",
        "\n",
        "# Evaluate model on test set\n",
        "cos_sim_scores = []\n",
        "for i in range(len(df)):\n",
        "    # Get ground truth and predicted responses\n",
        "    true_response = df.iloc[i]['response']\n",
        "    pred_response = model.predict(df.iloc[i]['utterance'])[0]\n",
        "    pred_response = ' '.join([index_to_word[i] for i in pred_response])\n",
        "    \n",
        "    # Calculate cosine similarity between word embeddings of ground truth and predicted responses\n",
        "    true_embedding = np.mean([w2v_model[word] for word in true_response.split()], axis=0)\n",
        "    pred_embedding = np.mean([w2v_model[word] for word in pred_response.split()], axis=0)\n",
        "    cos_sim_score = cosine_similarity([true_embedding], [pred_embedding])[0][0]\n",
        "    \n",
        "    cos_sim_scores.append(cos_sim_score)\n",
        "\n",
        "# Calculate mean cosine similarity score for test set\n",
        "mean_cos_sim_score = np.mean(cos_sim_scores)\n",
        "\n",
        "print(\"Mean cosine similarity score: \", mean_cos_sim_score)\n"
      ],
      "metadata": {
        "id": "j1uLZase-5Mq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}