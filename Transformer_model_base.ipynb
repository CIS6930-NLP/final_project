{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CIS6930-NLP/final_project/blob/main/Transformer_model_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For practice: Empathetic Response Generation on EmpatheticDialogues\n",
        "\n",
        "Paper for Empatheticdialogue Transformer model\n",
        "https://arxiv.org/pdf/2204.11320v1.pdf\n",
        " "
      ],
      "metadata": {
        "id": "0y_hTXc68zvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?id=1iXkrghQAzHF58ctIMWBMwpEk-L0EYlFi' />\n",
        "<figcaption>Transformer Architecture</figcaption></center>\n",
        "</figure>\n"
      ],
      "metadata": {
        "id": "gh5L5PxYLL5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JgF5wHdxMpN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import libraries"
      ],
      "metadata": {
        "id": "x8gleIUt84qE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aUEL2gBs8EXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94ca9a4-0e90-4f4b-c97b-33219e1b1cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.11.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "# import keras_nlp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# try:\n",
        "#     %tensorflow_version 2.x\n",
        "# except Exception:\n",
        "#     pass\n",
        "# import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "7FOOE_CnPSRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a68593-321a-450a-e171-c2cc1f969fb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check GPU availability\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDmtQxUvO_gB",
        "outputId": "ed1e8b05-5267-4837-e22f-01bbc57fb017"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data preprocessing"
      ],
      "metadata": {
        "id": "O3k9zaE-CPK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load data"
      ],
      "metadata": {
        "id": "Yg6V6MrU39_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = \"/content/drive/MyDrive/code/Updated Data/train.csv\"\n",
        "val_file = \"/content/drive/MyDrive/code/Updated Data/valid.csv\"\n",
        "test_file = \"/content/drive/MyDrive/code/Updated Data/test.csv\"\n",
        "def data_loading(filepath): \n",
        "  data = pd.read_csv(filepath, encoding = 'utf-8')\n",
        "  data = data.drop('conv_id', axis = 1)\n",
        "  data = data.drop('utterance_idx', axis = 1)\n",
        "  data = data.drop('speaker_idx', axis = 1)\n",
        "  data = data.drop('selfeval', axis = 1)\n",
        "  data = data.drop('tags', axis = 1)\n",
        "  data = data.dropna()\n",
        "  return data\n",
        "\n",
        "train_data = data_loading(train_file)\n",
        "val_data = data_loading(val_file)\n",
        "test_data = data_loading(test_file)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "0hbm71Pj3k8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7914c768-bd9e-43a3-b641-ce3385fd2625"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0      context                                             prompt  \\\n",
              "0           0  sentimental  I remember going to the fireworks with my best...   \n",
              "1           1  sentimental  I remember going to the fireworks with my best...   \n",
              "2           2  sentimental  I remember going to the fireworks with my best...   \n",
              "3           3  sentimental  I remember going to the fireworks with my best...   \n",
              "4           4  sentimental  I remember going to the fireworks with my best...   \n",
              "\n",
              "                                           utterance  \n",
              "0  I remember going to see the fireworks with my ...  \n",
              "1  Was this a friend you were in love with_comma_...  \n",
              "2                This was a best friend. I miss her.  \n",
              "3                                Where has she gone?  \n",
              "4                                 We no longer talk.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-676c7b41-e9ef-42c5-824c-024d9ff4d59f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>context</th>\n",
              "      <th>prompt</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>I remember going to see the fireworks with my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>Was this a friend you were in love with_comma_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>This was a best friend. I miss her.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>Where has she gone?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>We no longer talk.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-676c7b41-e9ef-42c5-824c-024d9ff4d59f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-676c7b41-e9ef-42c5-824c-024d9ff4d59f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-676c7b41-e9ef-42c5-824c-024d9ff4d59f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#emotion classifier\n",
        "def data_loading2(filepath): \n",
        "    data = pd.read_csv(filepath, encoding = 'utf-8')\n",
        "    data = data.drop('conv_id', axis = 1)\n",
        "    data = data.drop('utterance_idx', axis = 1)\n",
        "    data = data.drop('speaker_idx', axis = 1)\n",
        "    data = data.drop('selfeval', axis = 1)\n",
        "    data = data.drop('tags', axis = 1)\n",
        "    data = data.drop('utterance', axis = 1)\n",
        "\n",
        "    data = data.dropna()\n",
        "    return data\n",
        "\n",
        "train_data2 = data_loading(train_file)\n",
        "val_data2 = data_loading(val_file)\n",
        "test_data2 = data_loading(test_file)\n",
        "train_data2.head()"
      ],
      "metadata": {
        "id": "FoK2rQTC4DEx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "fce32ac3-92f2-4a0a-cd63-c463eb66559b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0      context                                             prompt  \\\n",
              "0           0  sentimental  I remember going to the fireworks with my best...   \n",
              "1           1  sentimental  I remember going to the fireworks with my best...   \n",
              "2           2  sentimental  I remember going to the fireworks with my best...   \n",
              "3           3  sentimental  I remember going to the fireworks with my best...   \n",
              "4           4  sentimental  I remember going to the fireworks with my best...   \n",
              "\n",
              "                                           utterance  \n",
              "0  I remember going to see the fireworks with my ...  \n",
              "1  Was this a friend you were in love with_comma_...  \n",
              "2                This was a best friend. I miss her.  \n",
              "3                                Where has she gone?  \n",
              "4                                 We no longer talk.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4159d6f5-46c2-459f-ade1-84f5fb572592\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>context</th>\n",
              "      <th>prompt</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>I remember going to see the fireworks with my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>Was this a friend you were in love with_comma_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>This was a best friend. I miss her.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>Where has she gone?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>sentimental</td>\n",
              "      <td>I remember going to the fireworks with my best...</td>\n",
              "      <td>We no longer talk.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4159d6f5-46c2-459f-ade1-84f5fb572592')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4159d6f5-46c2-459f-ade1-84f5fb572592 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4159d6f5-46c2-459f-ade1-84f5fb572592');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Grouping emotions \n",
        "emotions = {}\n",
        "emotions['excited'] = emotions['surprised'] = emotions['joyful'] = \"excited\"\n",
        "emotions['afraid'] = emotions['terrified'] = emotions['anxious']= emotions['apprehensive']='afraid'\n",
        "emotions['disgusted'] = emotions['embarrassed']= emotions['guilty'] = emotions['ashamed'] =\"disgusted\"\n",
        "emotions['angry'] = emotions ['annoyed'] = emotions['jealous'] =emotions[ 'furious' ] = \"annoyed\"\n",
        "emotions['faithful'] = emotions ['trusting']=emotions ['grateful']= emotions['caring'] = emotions['hopeful'] = \"grateful\"\n",
        "emotions['sad'] = emotions['disappointed'] = emotions['devastated']= emotions ['lonely']=emotions['nostalgic']=emotions['sentimental'] = \"disappointed\"\n",
        "emotions['proud']= emotions['impressed']= emotions['content'] = \"impressed\"\n",
        "emotions['anticipating']=emotions[ 'prepared']=emotions ['confident'] = \"prepared\"\n",
        "dicttt=emotions"
      ],
      "metadata": {
        "id": "X88GhBanDBVw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r\"i'm\", \"i am\", sentence)\n",
        "    sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
        "    sentence = re.sub(r\"she's\", \"she is\", sentence)\n",
        "    sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
        "    sentence = re.sub(r\"that's\", \"that is\", sentence)\n",
        "    sentence = re.sub(r\"what's\", \"what is\", sentence)\n",
        "    sentence = re.sub(r\"where's\", \"where is\", sentence)\n",
        "    sentence = re.sub(r\"how's\", \"how is\", sentence)\n",
        "    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n",
        "    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n",
        "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
        "    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n",
        "    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n",
        "    sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
        "    sentence = re.sub(r\"can't\", \"cannot\", sentence)\n",
        "    sentence = re.sub(r\"n't\", \" not\", sentence)\n",
        "    sentence = re.sub(r\"n'\", \"ng\", sentence)\n",
        "    sentence = re.sub(r\"'bout\", \"about\", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "MfuUJkG3ExKG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_context = train_data['context']\n",
        "train_question = train_data['prompt']\n",
        "train_answer = train_data['utterance']\n",
        "\n",
        "\n",
        "val_context = val_data['context']\n",
        "val_question = val_data['prompt']\n",
        "val_answer = val_data['utterance']\n",
        "\n",
        "test_context = test_data['context']\n",
        "test_question = test_data['prompt']\n",
        "test_answer = test_data['utterance']\n",
        "# print(len(train_context))\n",
        "# print(len(train_question))\n",
        "# print(len(train_answer))\n",
        "\n",
        "  # Maximum number of samples to preprocess\n",
        "MAX_SAMPLES = 50000\n",
        "\n",
        "train_context = [preprocess_sentence(emotions[sentence]) for sentence in train_context]\n",
        "train_questions = [preprocess_sentence(sentence) for sentence in train_question]\n",
        "train_answers = [preprocess_sentence(sentence) for sentence in train_answer]\n",
        "\n",
        "val_context = [preprocess_sentence(emotions[sentence]) for sentence in val_context]\n",
        "val_questions = [preprocess_sentence(sentence) for sentence in val_question]\n",
        "val_answers = [preprocess_sentence(sentence) for sentence in val_answer]\n",
        "\n",
        "test_context = [preprocess_sentence(emotions[sentence]) for sentence in test_context]\n",
        "test_questions = [preprocess_sentence(sentence) for sentence in test_question]\n",
        "test_answers = [preprocess_sentence(sentence) for sentence in test_answer]"
      ],
      "metadata": {
        "id": "RHrb_d_zRKaE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Sample context: {}'.format(train_context[20]))\n",
        "print('Sample question: {}'.format(train_questions[20]))\n",
        "print('Sample answer: {}'.format(train_answers[20]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVuolHCxF-J5",
        "outputId": "872961c5-054c-41d2-f82c-1037edade9c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample context: grateful\n",
            "Sample question: i have always been loyal to my wife .\n",
            "Sample answer: what do you mean it has not been easy ? how close have you come to cheating ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### emotion_classifier\n",
        "train_context2 = train_data2['context']\n",
        "train_question2 = train_data2['prompt']\n",
        "\n",
        "val_context2 = val_data2['context']\n",
        "val_question2 = val_data2['prompt']\n",
        "\n",
        "\n",
        "test_context2 = test_data2['context']\n",
        "test_question2 = test_data2['prompt']\n",
        "\n",
        "train_context2 = [preprocess_sentence(emotions[sentence]) for sentence in train_context]\n",
        "train_questions2 = [preprocess_sentence(sentence) for sentence in train_question]\n",
        "\n",
        "\n",
        "val_context2 = [preprocess_sentence(emotions[sentence]) for sentence in val_context]\n",
        "val_questions2 = [preprocess_sentence(sentence) for sentence in val_question]\n",
        "\n",
        "\n",
        "test_context2 = [preprocess_sentence(emotions[sentence]) for sentence in test_context]\n",
        "test_questions2 = [preprocess_sentence(sentence) for sentence in test_question]\n"
      ],
      "metadata": {
        "id": "jetRod7A2Fy6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperparameters "
      ],
      "metadata": {
        "id": "3vnEMsfXRUz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU {}'.format(tpu.cluster_spec().as_dict()['worker']))\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: {}\".format(strategy.num_replicas_in_sync))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj5nBF7TRuic",
        "outputId": "c87bef72-45a7-411b-f8d9-c626813e91a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPLICAS: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum sentence length\n",
        "MAX_LENGTH = 40\n",
        "\n",
        "# Maximum number of samples to preprocess\n",
        "MAX_SAMPLES = 50000\n",
        "\n",
        "# For tf.data.Dataset\n",
        "BATCH_SIZE = 64 * strategy.num_replicas_in_sync\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# For Transformer\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "EPOCHS = 100"
      ],
      "metadata": {
        "id": "cV3FHU-JRYbR"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenization\n"
      ],
      "metadata": {
        "id": "H8iUpclsGRfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build tokenizer using tfds for both questions and answers\n",
        "# changed \"features\" to \"deprecated\"\n",
        "\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    train_questions + train_answers + train_context , target_vocab_size=2**13)\n",
        "\n",
        "# Define start and end token to indicate the start and end of a sentence\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# Vocabulary size plus start and end token\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2"
      ],
      "metadata": {
        "id": "vhlmJ-nWG6Ha"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_questions[20])\n",
        "print('Tokenized sample question: {}'.format(tokenizer.encode(train_questions[20])))\n",
        "print(VOCAB_SIZE)\n",
        "print(tokenizer.decode([25]))\n",
        "print(START_TOKEN)\n",
        "print(END_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM1HDc_uG9l3",
        "outputId": "f2d7d10e-e48e-4e76-d788-b69ed7343d40"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i have always been loyal to my wife .\n",
            "Tokenized sample question: [1, 20, 98, 59, 1639, 5, 4, 744, 3]\n",
            "8174\n",
            "when \n",
            "[8172]\n",
            "[8173]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Input/output "
      ],
      "metadata": {
        "id": "UTQq7RmuIZHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize, filter and pad sentences\n",
        "def tokenize_and_filter(inputs, outputs, context):\n",
        "  tokenized_inputs, tokenized_outputs, tokenized_context = [], [], []\n",
        "  \n",
        "  for (sentence1, sentence2, emotion) in zip(inputs, outputs, context):\n",
        "    # tokenize sentence\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    emotion = tokenizer.encode(emotion)\n",
        "    # check tokenized sentence max length\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "      tokenized_context.append(emotion)\n",
        "  \n",
        "  # pad tokenized sentences\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
        "  \n",
        "  return tokenized_inputs, tokenized_outputs, tokenized_context\n",
        "\n",
        "\n",
        "questions, answers, context = tokenize_and_filter(train_questions, train_answers, train_context)"
      ],
      "metadata": {
        "id": "J8XvuJCnGQ9i"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(questions)))\n",
        "print(questions[20])\n",
        "print(questions[20][0], questions[20][-1])\n",
        "print(len(questions[20]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zpyc45U5GK99",
        "outputId": "7b116952-8698-44b9-9137-621c7f381dbf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 8174\n",
            "Number of samples: 76184\n",
            "[8172    6 2420  122  419   13    1   30  123   23   74   67  863  105\n",
            "    1   93   57    1   37   18  263   62    3 8173    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "8172 0\n",
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## create dataset"
      ],
      "metadata": {
        "id": "uK9iYMdbIhzV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'input1': questions,\n",
        "        'input2': context,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "9pTN1nYkIrBY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset,'\\n')\n",
        "dataset_iter_0 = iter(dataset).next()\n",
        "\n",
        "\n",
        "inp1  = dataset_iter_0[0]['input1'].numpy()[2]\n",
        "inp2 = dataset_iter_0[0]['input2'].numpy()[2]\n",
        "dec_inp = dataset_iter_0[0]['dec_inputs'].numpy()[2]\n",
        "out  = dataset_iter_0[1]['outputs'].numpy()[2]\n",
        "\n",
        "print('question: inputs[2] = ', inp1)\n",
        "print('context: inputs[2] = ', inp2)\n",
        "print('ans: dec_inputs[2] = ', dec_inp)\n",
        "print('ans: outputs[2] = ', out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukBxptnBI0Pu",
        "outputId": "85836532-2ae2-4d23-8a00-5e4f94f6b938"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset element_spec=({'input1': TensorSpec(shape=(None, 40), dtype=tf.int32, name=None), 'input2': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(None, 39), dtype=tf.int32, name=None)}, {'outputs': TensorSpec(shape=(None, 39), dtype=tf.int32, name=None)})> \n",
            "\n",
            "question: inputs[2] =  [8172    1  193    9 3737    5   76    5    6  137  565 5500   49   15\n",
            "  500    5 5242 7948    4  985    2    1    9   72   15  226  119 3737\n",
            "    8    1   37   18  890   11    5  736    3 8173    0    0]\n",
            "context: inputs[2] =  [48]\n",
            "ans: dec_inputs[2] =  [8172   11   39  422    2    1    9   67 3306  142   25    1  133   49\n",
            "   53   46   22 8173    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n",
            "ans: outputs[2] =  [  11   39  422    2    1    9   67 3306  142   25    1  133   49   53\n",
            "   46   22 8173    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Attention\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "_G5H2hJgdEe6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY370nW3I_pF",
        "outputId": "bf6b7b87-7f86-4c4e-a63b-8f6f8cc0c6de"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PrefetchDataset element_spec=({'input1': TensorSpec(shape=(None, 40), dtype=tf.int32, name=None), 'input2': TensorSpec(shape=(None, 1), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(None, 39), dtype=tf.int32, name=None)}, {'outputs': TensorSpec(shape=(None, 39), dtype=tf.int32, name=None)})>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "metadata": {
        "id": "035yWl3S9C58"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Masking"
      ],
      "metadata": {
        "id": "4rQtJ13z9ti9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "7521HobK9gtF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
      ],
      "metadata": {
        "id": "rMgGQg-n9yGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "319fbc2d-b44e-4aa3-b5f6-412269f753b6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 0. 1. 0. 1.]]]\n",
            "\n",
            "\n",
            " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look-ahead mask to mask the future tokens in a sequence.\n",
        "We also mask out pad tokens.\n",
        "\n",
        "i.e. To predict the third word, only the first and second word will be used"
      ],
      "metadata": {
        "id": "yZJQBxYa92AP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "metadata": {
        "id": "QizA6naP94bh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
      ],
      "metadata": {
        "id": "5C3U97WM97wM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36cd6f65-af0e-4c3a-bf72-1ceb72aab07f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[0. 1. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 1. 1.]\n",
            "   [0. 0. 1. 0. 1.]\n",
            "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class PositionalEncoding(layers.Layer): #inheriting from the Layers class\n",
        "\n",
        "#   def __init__(self, position, d_model):\n",
        "#     super(PositionalEncoding, self).__init__()\n",
        "#     self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "#   def get_angles(self, position, i, d_model):\n",
        "#     angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "#     return position * angles\n",
        "\n",
        "#   def positional_encoding(self, position, d_model):\n",
        "#     angle_rads = self.get_angles(\n",
        "#         position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "#         i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "#         d_model=d_model)\n",
        "#     # apply sin to even index in the array\n",
        "#     sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "#     # apply cos to odd index in the array\n",
        "#     cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "#     pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "#     pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "#     return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "#   def call(self, inputs):\n",
        "#     return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "metadata": {
        "id": "gm2RdDU0JDD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "  \n",
        "  def get_config(self):\n",
        "\n",
        "        config = super(PositionalEncoding, self).get_config()\n",
        "        config.update({\n",
        "            'position': self.position,\n",
        "            'd_model': self.d_model,\n",
        "            \n",
        "        })\n",
        "        return config\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "metadata": {
        "id": "yAusIsANTl2T"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "z1wFkc3-_SbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "#   inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "#   padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "#   attention = MultiHeadAttention(\n",
        "#       d_model, num_heads, name=\"attention\")({\n",
        "#           'query': inputs,\n",
        "#           'key': inputs,\n",
        "#           'value': inputs,\n",
        "#           'mask': padding_mask\n",
        "#       })\n",
        "#   attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "#   attention = tf.keras.layers.LayerNormalization(\n",
        "#       epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "#   outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "#   outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "#   outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "#   outputs = tf.keras.layers.LayerNormalization(\n",
        "#       epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "#   return tf.keras.Model(\n",
        "#       inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "JYHRGevE_mFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  add_attention = tf.keras.layers.add([inputs,attention])\n",
        "  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  add_attention = tf.keras.layers.add([attention,outputs])\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "2mQ2kRcVT3RF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def encoder(vocab_size,\n",
        "#             num_layers,\n",
        "#             units,\n",
        "#             d_model,\n",
        "#             num_heads,\n",
        "#             dropout,\n",
        "#             name=\"encoder\"):\n",
        "#   input1 = tf.keras.Input(shape=(None,), name=\"input1\")\n",
        "#   input2 = tf.keras.Input(shape=(None,), name=\"imput2\")\n",
        "#   padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "#   embedding1 = tf.keras.layers.Embedding(vocab_size, d_model)(input1)\n",
        "#   embedding1 *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "#   embedding2 = tf.keras.layers.Embedding(vocab_size, d_model)(input2)\n",
        "#   embedding2 *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "\n",
        "#   embeddings = outputs = tf.keras.layers.LayerNormalization(\n",
        "#       epsilon=1e-6)(embedding1 + embedding2)\n",
        "\n",
        "#   embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "#   outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "#   for i in range(num_layers):\n",
        "#     outputs = encoder_layer(\n",
        "#         units=units,\n",
        "#         d_model=d_model,\n",
        "#         num_heads=num_heads,\n",
        "#         dropout=dropout,\n",
        "#         name=\"encoder_layer_{}\".format(i),\n",
        "#     )([outputs, padding_mask])\n",
        "\n",
        "#   return tf.keras.Model(\n",
        "#       inputs=[input1,input2, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "TSPdxB41pWV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  input1 = tf.keras.Input(shape=(None,), name=\"input1\")\n",
        "  input2 = tf.keras.Input(shape=(None,), name=\"input2\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embedding1 = tf.keras.layers.Embedding(vocab_size, d_model)(input1)\n",
        "  embedding1 *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\n",
        "  \n",
        "  embedding2 = tf.keras.layers.Embedding(vocab_size, d_model)(input2)\n",
        "  embedding2 *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\n",
        "\n",
        "  embeddings = outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(embedding1 + embedding2)\n",
        "  embeddings = PositionalEncoding(vocab_size,d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[input1,input2, padding_mask], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "sy8q3MpDUd8Q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder"
      ],
      "metadata": {
        "id": "mwjNACY2_uxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "#   inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "#   enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "#   look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "#   padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "#   attention1 = MultiHeadAttention(\n",
        "#       d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "#           'query': inputs,\n",
        "#           'key': inputs,\n",
        "#           'value': inputs,\n",
        "#           'mask': look_ahead_mask\n",
        "#       })\n",
        "#   attention1 = tf.keras.layers.LayerNormalization(\n",
        "#       epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "#   attention2 = MultiHeadAttention(\n",
        "#       d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "#           'query': attention1,\n",
        "#           'key': enc_outputs,\n",
        "#           'value': enc_outputs,\n",
        "#           'mask': padding_mask\n",
        "#       })\n",
        "#   attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "#   attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "#   outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "#   outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "#   outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "#   outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "#   return tf.keras.Model(\n",
        "#       inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "#       outputs=outputs,\n",
        "#       name=name)"
      ],
      "metadata": {
        "id": "463NnSQB_elr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  add_attention = tf.keras.layers.add([attention1,inputs])    \n",
        "  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  add_attention = tf.keras.layers.add([attention2,attention1])\n",
        "  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  add_attention = tf.keras.layers.add([outputs,attention2])\n",
        "  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(add_attention)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "PpS2OwQuUHu2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def decoder(vocab_size,\n",
        "#             num_layers,\n",
        "#             units,\n",
        "#             d_model,\n",
        "#             num_heads,\n",
        "#             dropout,\n",
        "#             name='decoder'):\n",
        "#   inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "#   enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "#   look_ahead_mask = tf.keras.Input(\n",
        "#       shape=(1, None, None), name='look_ahead_mask')\n",
        "#   padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "#   embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "#   embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "#   embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "#   outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "#   for i in range(num_layers):\n",
        "#     outputs = decoder_layer(\n",
        "#         units=units,\n",
        "#         d_model=d_model,\n",
        "#         num_heads=num_heads,\n",
        "#         dropout=dropout,\n",
        "#         name='decoder_layer_{}'.format(i),\n",
        "#     )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "#   return tf.keras.Model(\n",
        "#       inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "#       outputs=outputs,\n",
        "#       name=name)"
      ],
      "metadata": {
        "id": "DZGFOCvN_z1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.keras.layers.Lambda(lambda d_model: tf.math.sqrt(tf.cast(d_model, tf.float32)))(d_model)\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "metadata": {
        "id": "_DQzoqqbUSQV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  input1 = tf.keras.Input(shape=(None,), name=\"input1\")\n",
        "  input2 = tf.keras.Input(shape=(None,), name=\"input2\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(input1)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(input1)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[input1, input2, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[input1, input2, dec_inputs], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "d-4FBI6u_3PA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  input1 = tf.keras.Input(shape=(None,), name=\"input1\")\n",
        "  input2 = tf.keras.Input(shape=(None,), name=\"input2\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(input1)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(input1)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[input1,input2, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[input1,input2, dec_inputs], outputs=outputs, name=name)"
      ],
      "metadata": {
        "id": "iRzetcGyVG0N"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_transformer = transformer(\n",
        "    vocab_size=8192,\n",
        "    num_layers=4,\n",
        "    units=512,\n",
        "    d_model=128,\n",
        "    num_heads=4,\n",
        "    dropout=0.3,\n",
        "    name=\"sample_transformer\")\n",
        "\n",
        "# tf.keras.utils.plot_model(\n",
        "#     sample_transformer, to_file='transformer.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "bZ4xUYHpVhQ9"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "YkMaiC_JAlCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "NUM_LAYERS = 2\n",
        "D_MODEL = 256\n",
        "NUM_HEADS = 8\n",
        "UNITS = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "model = transformer(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT)"
      ],
      "metadata": {
        "id": "shncnmu0Ak48"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss function\n",
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")"
      ],
      "metadata": {
        "id": "ZA42_UZCAjMs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#custom learning rate\n",
        "# class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "#   def __init__(self, d_model, warmup_steps=4000):\n",
        "#     super(CustomSchedule, self).__init__()\n",
        "\n",
        "#     self.d_model = d_model\n",
        "#     self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "#     self.warmup_steps = warmup_steps\n",
        "\n",
        "#   def __call__(self, step):\n",
        "#     arg1 = tf.math.rsqrt(step)\n",
        "#     arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "#     return tf.math.rsqrt(tf.cast(self.d_model, tf.float32)) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "7f4YDQrcAvpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = tf.constant(d_model,dtype=tf.float32)\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def get_config(self):\n",
        "        return {\"d_model\": self.d_model,\"warmup_steps\":self.warmup_steps}\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.multiply(tf.math.rsqrt(self.d_model), tf.math.minimum(arg1, arg2))"
      ],
      "metadata": {
        "id": "u4NsFdpwXIMq"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "metadata": {
        "id": "YYMy0tzvDuGO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "a575603e-00a5-487f-d161-ea39d485ced1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxIp5tvd3xtN",
        "outputId": "d9ecbac6-4340-4904-ae14-d219fd3c6ea9"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.CustomSchedule object at 0x7f433f85bbb0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile"
      ],
      "metadata": {
        "id": "_yqKmtMDBTYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0014, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "# initialize and compile model within strategy scope\n",
        "with strategy.scope():\n",
        "  model = transformer(\n",
        "      vocab_size=VOCAB_SIZE,\n",
        "      num_layers=NUM_LAYERS,\n",
        "      units=UNITS,\n",
        "      d_model=D_MODEL,\n",
        "      num_heads=NUM_HEADS,\n",
        "      dropout=DROPOUT)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD1oABMSXRCT",
        "outputId": "b8f3d0fe-8792-4665-e427-ef36583ec244"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input1 (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input2 (InputLayer)            [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['input1[0][0]']                 \n",
            "                                                                                                  \n",
            " encoder (Functional)           (None, None, 256)    5239808     ['input1[0][0]',                 \n",
            "                                                                  'input2[0][0]',                 \n",
            "                                                                  'enc_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
            "                                e)                                                                \n",
            "                                                                                                  \n",
            " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['input1[0][0]']                 \n",
            "                                                                                                  \n",
            " decoder (Functional)           (None, None, 256)    3674112     ['dec_inputs[0][0]',             \n",
            "                                                                  'encoder[0][0]',                \n",
            "                                                                  'look_ahead_mask[0][0]',        \n",
            "                                                                  'dec_padding_mask[0][0]']       \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, None, 8174)   2100718     ['decoder[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,014,638\n",
            "Trainable params: 11,014,638\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint_path = \"/content/drive/MyDrive/code/transformer_ckpt/\"\n",
        "\n",
        "# ckpt = tf.train.Checkpoint(transformer=model,\n",
        "#                            optimizer=optimizer)\n",
        "\n",
        "# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# if ckpt_manager.latest_checkpoint:\n",
        "#     ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "#     print(\"Latest checkpoint restored!\")\n"
      ],
      "metadata": {
        "id": "Cmttf8U8BOuc"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ],
      "metadata": {
        "id": "HFwHWqlHIpHu"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(optimizer = 'adam',loss = 'sparse_categorical_crossentropy', metrics=[accuracy])"
      ],
      "metadata": {
        "id": "r-ZuzSgYIjoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EPOCHS = 10\n",
        "# for epoch in range(EPOCHS):\n",
        "#     print(\"Start of epoch {}\".format(epoch+1))\n",
        "#     start = time.time()\n",
        "\n",
        "#     train_loss.reset_states()\n",
        "#     train_accuracy.reset_states()\n",
        "\n",
        "#     for (batch, (enc_inputs, y_true)) in enumerate(dataset):\n",
        "#         dec_inputs = y_true[:, :-1]\n",
        "#         dec_outputs_real = y_true[:, 1:]\n",
        "\n",
        "#         with tf.GradientTape() as tape:\n",
        "#             predictions = transformer(enc_inputs, dec_inputs, True)\n",
        "#             loss = loss_function(dec_outputs_real, predictions)\n",
        "\n",
        "#         gradients = tape.gradient(loss, transformer.trainable_variables,)\n",
        "#         optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "#         train_loss(loss)\n",
        "#         train_accuracy(dec_outputs_real, predictions)\n",
        "\n",
        "#         print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(\n",
        "#                 epoch+1, batch, train_loss.result(), train_accuracy.result()))\n",
        "\n",
        "#         if batch % 2 == 0:\n",
        "#             print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(\n",
        "#                 epoch+1, batch, train_loss.result(), train_accuracy.result()))\n",
        "    \n",
        "\n",
        "#     ckpt_save_path = ckpt_manager.save()\n",
        "#     print(\"Saving checkpont for epoch {} at {}\".format(epoch+1, ckpt_save_path))\n",
        "#     print(\"time taken for 1 epoch: {} secs\\n\".format(time.time() - start))\n",
        "\n",
        "# model.fit(dataset, epochs=EPOCHS)\n",
        "# ckpt_save_path = ckpt_manager.save()\n",
        "# print(\"Saving checkpont for epoch {} at {}\".format(epoch+1, ckpt_save_path))\n",
        "# print(\"time taken for 1 epoch: {} secs\\n\".format(time.time() - start))"
      ],
      "metadata": {
        "id": "Sgs33X_MEmzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vb-aC-xYtmU",
        "outputId": "bec3574b-ceed-4e2b-90cd-ac0f1b3891fd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1191/1191 [==============================] - 172s 120ms/step - loss: 1.8490 - accuracy: 0.0920\n",
            "Epoch 2/100\n",
            "1191/1191 [==============================] - 83s 69ms/step - loss: 1.6009 - accuracy: 0.1131\n",
            "Epoch 3/100\n",
            "1191/1191 [==============================] - 86s 72ms/step - loss: 1.5305 - accuracy: 0.1189\n",
            "Epoch 4/100\n",
            "1191/1191 [==============================] - 87s 73ms/step - loss: 1.4845 - accuracy: 0.1228\n",
            "Epoch 5/100\n",
            "1191/1191 [==============================] - 78s 66ms/step - loss: 1.4510 - accuracy: 0.1256\n",
            "Epoch 6/100\n",
            "1191/1191 [==============================] - 75s 63ms/step - loss: 1.4239 - accuracy: 0.1277\n",
            "Epoch 7/100\n",
            "1191/1191 [==============================] - 82s 69ms/step - loss: 1.4032 - accuracy: 0.1292\n",
            "Epoch 8/100\n",
            "1191/1191 [==============================] - 90s 76ms/step - loss: 1.3852 - accuracy: 0.1305\n",
            "Epoch 9/100\n",
            "1191/1191 [==============================] - 90s 75ms/step - loss: 1.3689 - accuracy: 0.1319\n",
            "Epoch 10/100\n",
            "1191/1191 [==============================] - 87s 73ms/step - loss: 1.3548 - accuracy: 0.1329\n",
            "Epoch 11/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.3415 - accuracy: 0.1341\n",
            "Epoch 12/100\n",
            "1191/1191 [==============================] - 75s 63ms/step - loss: 1.3295 - accuracy: 0.1351\n",
            "Epoch 13/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.3191 - accuracy: 0.1361\n",
            "Epoch 14/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.3091 - accuracy: 0.1370\n",
            "Epoch 15/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.3000 - accuracy: 0.1375\n",
            "Epoch 16/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.2922 - accuracy: 0.1385\n",
            "Epoch 17/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.2850 - accuracy: 0.1390\n",
            "Epoch 18/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.2778 - accuracy: 0.1395\n",
            "Epoch 19/100\n",
            "1191/1191 [==============================] - 74s 62ms/step - loss: 1.2712 - accuracy: 0.1404\n",
            "Epoch 20/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.2649 - accuracy: 0.1409\n",
            "Epoch 21/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.2588 - accuracy: 0.1414\n",
            "Epoch 22/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.2545 - accuracy: 0.1419\n",
            "Epoch 23/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.2497 - accuracy: 0.1423\n",
            "Epoch 24/100\n",
            "1191/1191 [==============================] - 71s 60ms/step - loss: 1.2441 - accuracy: 0.1431\n",
            "Epoch 25/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.2388 - accuracy: 0.1435\n",
            "Epoch 26/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.2348 - accuracy: 0.1441\n",
            "Epoch 27/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.2303 - accuracy: 0.1445\n",
            "Epoch 28/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.2254 - accuracy: 0.1451\n",
            "Epoch 29/100\n",
            "1191/1191 [==============================] - 74s 62ms/step - loss: 1.2210 - accuracy: 0.1456\n",
            "Epoch 30/100\n",
            "1191/1191 [==============================] - 75s 63ms/step - loss: 1.2173 - accuracy: 0.1462\n",
            "Epoch 31/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.2125 - accuracy: 0.1467\n",
            "Epoch 32/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.2073 - accuracy: 0.1472\n",
            "Epoch 33/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.2032 - accuracy: 0.1480\n",
            "Epoch 34/100\n",
            "1191/1191 [==============================] - 76s 64ms/step - loss: 1.1996 - accuracy: 0.1481\n",
            "Epoch 35/100\n",
            "1191/1191 [==============================] - 75s 63ms/step - loss: 1.1947 - accuracy: 0.1489\n",
            "Epoch 36/100\n",
            "1191/1191 [==============================] - 74s 62ms/step - loss: 1.1921 - accuracy: 0.1492\n",
            "Epoch 37/100\n",
            "1191/1191 [==============================] - 73s 62ms/step - loss: 1.1886 - accuracy: 0.1495\n",
            "Epoch 38/100\n",
            "1191/1191 [==============================] - 73s 62ms/step - loss: 1.1852 - accuracy: 0.1502\n",
            "Epoch 39/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1797 - accuracy: 0.1507\n",
            "Epoch 40/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.1752 - accuracy: 0.1512\n",
            "Epoch 41/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.1723 - accuracy: 0.1517\n",
            "Epoch 42/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1685 - accuracy: 0.1521\n",
            "Epoch 43/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.1639 - accuracy: 0.1528\n",
            "Epoch 44/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1598 - accuracy: 0.1532\n",
            "Epoch 45/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1567 - accuracy: 0.1536\n",
            "Epoch 46/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.1552 - accuracy: 0.1539\n",
            "Epoch 47/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.1527 - accuracy: 0.1542\n",
            "Epoch 48/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.1498 - accuracy: 0.1544\n",
            "Epoch 49/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.1459 - accuracy: 0.1551\n",
            "Epoch 50/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1448 - accuracy: 0.1552\n",
            "Epoch 51/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.1421 - accuracy: 0.1556\n",
            "Epoch 52/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.1384 - accuracy: 0.1560\n",
            "Epoch 53/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.1351 - accuracy: 0.1565\n",
            "Epoch 54/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.1315 - accuracy: 0.1570\n",
            "Epoch 55/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1291 - accuracy: 0.1574\n",
            "Epoch 56/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.1262 - accuracy: 0.1577\n",
            "Epoch 57/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1229 - accuracy: 0.1582\n",
            "Epoch 58/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1189 - accuracy: 0.1586\n",
            "Epoch 59/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1149 - accuracy: 0.1592\n",
            "Epoch 60/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1124 - accuracy: 0.1596\n",
            "Epoch 61/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.1107 - accuracy: 0.1600\n",
            "Epoch 62/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1099 - accuracy: 0.1599\n",
            "Epoch 63/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.1084 - accuracy: 0.1603\n",
            "Epoch 64/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.1059 - accuracy: 0.1605\n",
            "Epoch 65/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.1025 - accuracy: 0.1610\n",
            "Epoch 66/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.0995 - accuracy: 0.1616\n",
            "Epoch 67/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.0971 - accuracy: 0.1618\n",
            "Epoch 68/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.0945 - accuracy: 0.1622\n",
            "Epoch 69/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0928 - accuracy: 0.1623\n",
            "Epoch 70/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.0891 - accuracy: 0.1630\n",
            "Epoch 71/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0871 - accuracy: 0.1632\n",
            "Epoch 72/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0852 - accuracy: 0.1634\n",
            "Epoch 73/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.0830 - accuracy: 0.1637\n",
            "Epoch 74/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0815 - accuracy: 0.1639\n",
            "Epoch 75/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.0793 - accuracy: 0.1644\n",
            "Epoch 76/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0766 - accuracy: 0.1647\n",
            "Epoch 77/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0754 - accuracy: 0.1648\n",
            "Epoch 78/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0721 - accuracy: 0.1653\n",
            "Epoch 79/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.0709 - accuracy: 0.1655\n",
            "Epoch 80/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0671 - accuracy: 0.1661\n",
            "Epoch 81/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0651 - accuracy: 0.1664\n",
            "Epoch 82/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.0643 - accuracy: 0.1664\n",
            "Epoch 83/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0618 - accuracy: 0.1669\n",
            "Epoch 84/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.0599 - accuracy: 0.1670\n",
            "Epoch 85/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0593 - accuracy: 0.1670\n",
            "Epoch 86/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0574 - accuracy: 0.1672\n",
            "Epoch 87/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0569 - accuracy: 0.1677\n",
            "Epoch 88/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0528 - accuracy: 0.1682\n",
            "Epoch 89/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0513 - accuracy: 0.1683\n",
            "Epoch 90/100\n",
            "1191/1191 [==============================] - 72s 60ms/step - loss: 1.0481 - accuracy: 0.1688\n",
            "Epoch 91/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0471 - accuracy: 0.1690\n",
            "Epoch 92/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0455 - accuracy: 0.1691\n",
            "Epoch 93/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0437 - accuracy: 0.1695\n",
            "Epoch 94/100\n",
            "1191/1191 [==============================] - 79s 66ms/step - loss: 1.0418 - accuracy: 0.1697\n",
            "Epoch 95/100\n",
            "1191/1191 [==============================] - 74s 62ms/step - loss: 1.0404 - accuracy: 0.1700\n",
            "Epoch 96/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0394 - accuracy: 0.1701\n",
            "Epoch 97/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0383 - accuracy: 0.1702\n",
            "Epoch 98/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0375 - accuracy: 0.1704\n",
            "Epoch 99/100\n",
            "1191/1191 [==============================] - 73s 61ms/step - loss: 1.0373 - accuracy: 0.1702\n",
            "Epoch 100/100\n",
            "1191/1191 [==============================] - 72s 61ms/step - loss: 1.0343 - accuracy: 0.1709\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f433efd6ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model and load\n",
        "model.save('/content/drive/MyDrive/code/sample_tf_base_model') \n",
        "\n",
        "tf_base_model = tf.keras.models.load_model('/content/drive/MyDrive/code/sample_tf_base_model')\n",
        "\n",
        "# Check its architecture\n",
        "# tf_base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "A7qaF17j7cWn",
        "outputId": "91be15ee-e940-4b97-f865-c8f2e9819705"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, dense_1_layer_call_fn, dense_1_layer_call_and_return_conditional_losses, dense_2_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-a912acb5c3de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save model and load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/code/sample_tf_base_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf_base_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/code/sample_tf_base_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-87dcff0977dc>\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         config.update({\n\u001b[1;32m     11\u001b[0m             \u001b[0;34m'position'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/code/sample_tf_base_model.h5') \n",
        "\n",
        "# tf_base_model_h5 = tf.keras.models.load_model('/content/drive/MyDrive/code/tf_base_model.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "# tf_base_model_h5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "B3mGt4BD70K0",
        "outputId": "b09fe966-6be5-43fd-fb1c-9571514495bc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-750624eed33d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/code/sample_tf_base_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# tf_base_model_h5 = tf.keras.models.load_model('/content/drive/MyDrive/code/tf_base_model.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Show the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-87dcff0977dc>\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPositionalEncoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         config.update({\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0;34m'position'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;34m'd_model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PositionalEncoding' object has no attribute 'position'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence, context):\n",
        "  sentence = preprocess_sentence(str(sentence))\n",
        "  context = preprocess_sentence(str(context))\n",
        "\n",
        "  sentence = tf.expand_dims(START_TOKEN + tokenizer.encode(str(sentence)) + END_TOKEN, axis=0)\n",
        "  context = tokenizer.encode(str(context))\n",
        "\n",
        "  # input = tf.concat([sentence, context], -1)  \n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, context, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence, context):\n",
        "  prediction = evaluate(sentence,context)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Context: {}'.format(context))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "metadata": {
        "id": "n5mMn7ziHIpC"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = predict('Where have you been?', 'grateful')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZloViFl4YZk",
        "outputId": "9aeb1fc2-f94b-4930-8de0-65b69f9d5a5d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Where have you been?\n",
            "Context: grateful\n",
            "Output: i am so thankful for everything in my life .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(evaluate(\"Hello how are you?\", \"grateful\"))"
      ],
      "metadata": {
        "id": "dQhq64WEKbUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d0a2aa-a084-4e7f-a0fd-63e120c8e902"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[8172    1   14  254    5  221  118    2   45   21   58  207   96 1102\n",
            "  125  646   29], shape=(17,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def translate(sentence, context):\n",
        "#     output = evaluate(sentence, context).numpy()\n",
        "\n",
        "#     predicted_sentence = tokenizer.decode(\n",
        "#         [i for i in output if i < VOCAB_SIZE-2]\n",
        "#     )\n",
        "\n",
        "#     print(\"Input: {}\".format(sentence))\n",
        "#     print(\"Output: {}\".format(predicted_sentence))"
      ],
      "metadata": {
        "id": "3jJa5TmdKrfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# translate(\"Hello how are you\", \"grateful\")"
      ],
      "metadata": {
        "id": "Bfzs6H5JJs8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feed the model with its previous output - need to predic context\n",
        "# need to make changes to the context \n",
        "sentence = 'i have always been loyal to my wife.'\n",
        "\n",
        "## need an emotional classifier as well as a response prefix...\n",
        "context = 'grateful'\n",
        "for _ in range(5):\n",
        "  sentence = predict(sentence, context)\n",
        "  print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fms0bSxZvQ3",
        "outputId": "c7074f78-dfe0-435e-d932-78eb1d737b9f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: i have always been loyal to my wife.\n",
            "Context: grateful\n",
            "Output: i have been married for years . i have been married for years . i have been married for about years now .\n",
            "\n",
            "Input: i have been married for years . i have been married for years . i have been married for about years now .\n",
            "Context: grateful\n",
            "Output: i have been married for ten years now . i have been married for years\n",
            "\n",
            "Input: i have been married for ten years now . i have been married for years\n",
            "Context: grateful\n",
            "Output: i have been married for years . i have been married for years .\n",
            "\n",
            "Input: i have been married for years . i have been married for years .\n",
            "Context: grateful\n",
            "Output: i have been married for years . i have been married for years .\n",
            "\n",
            "Input: i have been married for years . i have been married for years .\n",
            "Context: grateful\n",
            "Output: i have been married for years . i have been married for years .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Emotion classifier Model"
      ],
      "metadata": {
        "id": "RktyRJl02wTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df2 = pd.DataFrame({'label' : train_context2,\n",
        "                'utterance' : train_questions2}, \n",
        "                                columns=['label','utterance'])\n",
        "val_df2 = pd.DataFrame({'label' : val_context2,\n",
        "                'utterance' : val_questions2}, \n",
        "                                columns=['label','utterance'])\n",
        "test_df2 = pd.DataFrame({'label' : test_context2,\n",
        "                'utterance' : test_questions2}, \n",
        "                                columns=['label','utterance'])"
      ],
      "metadata": {
        "id": "GNWA8YwlpRCK"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df2['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZMrrVTH281w",
        "outputId": "f969b5e6-40e8-4976-80f5-6e5e85e93fdc"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "disappointed    15519\n",
              "grateful        11596\n",
              "annoyed         11074\n",
              "afraid          10100\n",
              "excited         10083\n",
              "disgusted        9935\n",
              "impressed        8042\n",
              "prepared         7818\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "\n",
        "X_train2 = train_df2['utterance']\n",
        "y_train2 = train_df2['label']\n",
        "\n",
        "\n",
        "# X_val2 = val_df2['utterance']\n",
        "# y_val2 = val_df2['label']\n",
        "\n",
        "# X_test2 = test_df2['utterance']\n",
        "# y_test2 = test_df2['label']"
      ],
      "metadata": {
        "id": "3qzIWye84zZ1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cv \n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(X_train2)\n",
        "# print(X_test_cv.shape)\n",
        "# print(X_val_cv.shape)\n",
        "\n",
        "\n",
        "# print(y_test.shape)\n",
        "# print(y_train.shape)"
      ],
      "metadata": {
        "id": "OauW373c47eD"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_train2, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "yDyF_1he4-na"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model_logit = LogisticRegression()\n",
        "model_logit.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "xEKrc3d95jNv",
        "outputId": "4a66e25d-8553-464a-b8af-630e9a1427e5"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_logit.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPbO36kW5nYO",
        "outputId": "4a601dbd-720a-4c12-cee2-0b899629f481"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8560267857142857"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(text,model):\n",
        "    myvect = cv.transform([text]).toarray()\n",
        "    prediction = model.predict(myvect)\n",
        "#     pred_percentage = dict(zip(model.classes_,model.predict_proba(vect)[0]))\n",
        "    print(prediction)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "FkqNsZsS5s-W"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_output = str(predict_emotion(\"I am the best\",model_logit))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmQ8SBTa5vYl",
        "outputId": "7c9e1e02-ceb8-41b3-e23f-ffc3ef17aa6f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['grateful']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "# model_logit.save('/content/drive/MyDrive/code/em_clf_model') \n",
        "# model_logit.save('/content/drive/MyDrive/code/em_clf_model.h5') \n",
        "import pickle\n",
        "\n",
        "filepath= '/content/drive/MyDrive/code/em_clf_mode.pkl'\n",
        "with open('/content/drive/MyDrive/code/em_clf_model_pickle', 'wb') as f:\n",
        "  pickle.dump(model_logit,f)"
      ],
      "metadata": {
        "id": "Dil8hTxh5zDN"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bu6ZFWejeEes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence):\n",
        "  context = str(predict_emotion(sentence,model_logit))\n",
        "  prediction = evaluate(sentence,context)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "  \n",
        "  print('Context: {}'.format(context))\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "metadata": {
        "id": "AAxo5FIC6L9O"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need to make changes to the context \n",
        "sentence = 'i have always been loyal to my wife.'\n",
        "\n",
        "## need an emotional classifier as well as a response prefix...\n",
        "# context = 'grateful'\n",
        "for _ in range(5):\n",
        "  sentence = predict(sentence)\n",
        "  print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC9sMwr85_kD",
        "outputId": "ab6c74df-4e15-4325-ab32-d3329360d55e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['grateful']\n",
            "Context: ['grateful']\n",
            "Input: i have always been loyal to my wife.\n",
            "Output: i have been married for years . i have been married for years . i have been married for about years now .\n",
            "\n",
            "['grateful']\n",
            "Context: ['grateful']\n",
            "Input: i have been married for years . i have been married for years . i have been married for about years now .\n",
            "Output: i have been married for ten years now . i have been married for years\n",
            "\n",
            "['excited']\n",
            "Context: ['excited']\n",
            "Input: i have been married for ten years now . i have been married for years\n",
            "Output: i have been married for ten years now . i am so happy for him comma i have a relationship with him\n",
            "\n",
            "['grateful']\n",
            "Context: ['grateful']\n",
            "Input: i have been married for ten years now . i am so happy for him comma i have a relationship with him\n",
            "Output: i have been married for years . i have been married for years . i have been married for years and have been married for years\n",
            "\n",
            "['grateful']\n",
            "Context: ['grateful']\n",
            "Input: i have been married for years . i have been married for years . i have been married for years and have been married for years\n",
            "Output: i have been married for years . i have been married for years .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ds8vJ-iV5_5b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}